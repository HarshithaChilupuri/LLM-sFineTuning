{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWBdllhm9b+uuK2e4yRAog",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6e7024e6b1ad49ccbbfeddd4e0a78c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0ab68a45d4840e19370564a5b456f3c",
              "IPY_MODEL_57877f1b2b7f409d98e344badb77dd6c",
              "IPY_MODEL_6e51e33284874e488261ce13c75b0239"
            ],
            "layout": "IPY_MODEL_6ece7a6d0fb8412dbb5265271f961ea4"
          }
        },
        "e0ab68a45d4840e19370564a5b456f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2f6f69e9c2e4294a5743c3a14facc7d",
            "placeholder": "​",
            "style": "IPY_MODEL_6abb53b421d04f4ebc2f5cb79b2cc79e",
            "value": "Map: 100%"
          }
        },
        "57877f1b2b7f409d98e344badb77dd6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b47112ef154f4e4cac9bfc497e0b8770",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1cf71a2c70c4777ba6caa3c72dc815f",
            "value": 1000
          }
        },
        "6e51e33284874e488261ce13c75b0239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1ae81fb96784e01801385b36ec40813",
            "placeholder": "​",
            "style": "IPY_MODEL_ca6e07072b464775ba5d6de742e029cc",
            "value": " 1000/1000 [00:02&lt;00:00, 479.03 examples/s]"
          }
        },
        "6ece7a6d0fb8412dbb5265271f961ea4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2f6f69e9c2e4294a5743c3a14facc7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6abb53b421d04f4ebc2f5cb79b2cc79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b47112ef154f4e4cac9bfc497e0b8770": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1cf71a2c70c4777ba6caa3c72dc815f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1ae81fb96784e01801385b36ec40813": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca6e07072b464775ba5d6de742e029cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshithaChilupuri/LLM-sFineTuning/blob/main/Untitled29.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kWcP9nnOOezO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft\n",
        "!pip install evaluate # install the missing package"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0PJFsbTQHXO",
        "outputId": "48e0c3a5-26b9-4748-dbb5-ee252d849d22"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.4.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.32.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.15.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict, Dataset\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer)\n",
        "\n",
        "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
        "import evaluate\n",
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "mF3IyUM-OiAk"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = 'distilbert-base-uncased'\n",
        "\n",
        "#define label maps\n",
        "id2label = {0: \"Negative\", 1: \"Positive\"}\n",
        "label2id = {\"Negative\":0, \"Positive\":1}\n",
        "\n",
        "#generate classification model from model_checkpoint\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_checkpoint, num_labels =2, id2label=id2label, label2id = label2id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfT7spaHOh8e",
        "outputId": "39d48fda-850f-4bb1-efad-5ea583a01608"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset\n",
        "dataset = load_dataset(\"shawhin/imdb-truncated\")\n"
      ],
      "metadata": {
        "id": "XrghJJE_Oh6m"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset #Considered a dataset of only 1000 records and can select datsets with much lower values once we fine tune the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZLzsS5xOh5N",
        "outputId": "017bdda2-ed5f-44b3-ca13-100c2d7de85d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess data\n",
        "#create tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n",
        "\n",
        "#Converting text to numerical form for Machine understandability\n",
        "# create tokenize function\n",
        "def tokenize_function(examples):\n",
        "    # extract text\n",
        "    text = examples[\"text\"]\n",
        "\n",
        "    #tokenize and truncate text\n",
        "    tokenizer.truncation_side = \"left\" #truncating the long sequnces of data\n",
        "    tokenized_inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"np\",\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "    return tokenized_inputs\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfwr8OSZOh3u",
        "outputId": "f1464744-dd3c-41d4-d803-a8772df87f60"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "   # add pad token if none exists\n",
        "if tokenizer.pad_token is None: #padding the data if its a short sequence\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "    model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "id": "OAWav2knTKLU"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get a tokenized version of the dataset I've chosen"
      ],
      "metadata": {
        "id": "12rln-WYT_2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize training and validation datasets\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "6e7024e6b1ad49ccbbfeddd4e0a78c1c",
            "e0ab68a45d4840e19370564a5b456f3c",
            "57877f1b2b7f409d98e344badb77dd6c",
            "6e51e33284874e488261ce13c75b0239",
            "6ece7a6d0fb8412dbb5265271f961ea4",
            "d2f6f69e9c2e4294a5743c3a14facc7d",
            "6abb53b421d04f4ebc2f5cb79b2cc79e",
            "b47112ef154f4e4cac9bfc497e0b8770",
            "a1cf71a2c70c4777ba6caa3c72dc815f",
            "d1ae81fb96784e01801385b36ec40813",
            "ca6e07072b464775ba5d6de742e029cc"
          ]
        },
        "id": "hw8n7UEeOh20",
        "outputId": "bc0ab2f8-b108-4f2a-916a-891be46d6c48"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e7024e6b1ad49ccbbfeddd4e0a78c1c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create datacollator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "data_collator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8zTY_CdOhzT",
        "outputId": "ce36047f-5346-456c-e0d7-d752d5fed5f2"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataCollatorWithPadding(tokenizer=DistilBertTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
              "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}, padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation Metrics\n",
        "import evaluate\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "accuracy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fchjkfcAOhxp",
        "outputId": "1bd15616-e897-4436-dd00-0b72b3b75c3d"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EvaluationModule(name: \"accuracy\", module_type: \"metric\", features: {'predictions': Value(dtype='int32', id=None), 'references': Value(dtype='int32', id=None)}, usage: \"\"\"\n",
              "Args:\n",
              "    predictions (`list` of `int`): Predicted labels.\n",
              "    references (`list` of `int`): Ground truth labels.\n",
              "    normalize (`boolean`): If set to False, returns the number of correctly classified samples. Otherwise, returns the fraction of correctly classified samples. Defaults to True.\n",
              "    sample_weight (`list` of `float`): Sample weights Defaults to None.\n",
              "\n",
              "Returns:\n",
              "    accuracy (`float` or `int`): Accuracy score. Minimum possible value is 0. Maximum possible value is 1.0, or the number of examples input, if `normalize` is set to `True`.. A higher score means higher accuracy.\n",
              "\n",
              "Examples:\n",
              "\n",
              "    Example 1-A simple example\n",
              "        >>> accuracy_metric = evaluate.load(\"accuracy\")\n",
              "        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0])\n",
              "        >>> print(results)\n",
              "        {'accuracy': 0.5}\n",
              "\n",
              "    Example 2-The same as Example 1, except with `normalize` set to `False`.\n",
              "        >>> accuracy_metric = evaluate.load(\"accuracy\")\n",
              "        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], normalize=False)\n",
              "        >>> print(results)\n",
              "        {'accuracy': 3.0}\n",
              "\n",
              "    Example 3-The same as Example 1, except with `sample_weight` set.\n",
              "        >>> accuracy_metric = evaluate.load(\"accuracy\")\n",
              "        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], sample_weight=[0.5, 2, 0.7, 0.5, 9, 0.4])\n",
              "        >>> print(results)\n",
              "        {'accuracy': 0.8778625954198473}\n",
              "\"\"\", stored examples: 0)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Evaluation Metrics to Monitor the Performance of the LLM Model"
      ],
      "metadata": {
        "id": "zHkAlYObUejb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p):\n",
        "  predictions, labels = p\n",
        "  predictions = np.argmax(predictions, axis =1)\n",
        "  return{\"accuracy\":accuracy.compute(predictions=predictions,references=labels)}"
      ],
      "metadata": {
        "id": "WJ4OGY-NOhvb"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define list of examples\n",
        "text_list = [\"The most greatest of all time\",\"It was good.\", \"Not a fan, don't recommed.\", \"Better than the first one.\", \"This is not worth watching even once.\", \"This one is a pass.\",\"I Love This\"]\n",
        "\n",
        "print(\"Untrained model predictions:\")\n",
        "print(\"----------------------------\")\n",
        "for text in text_list:\n",
        "    # tokenize text\n",
        "    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "\n",
        "    # compute logits\n",
        "    logits = model(inputs).logits\n",
        "\n",
        "    # convert logits to label\n",
        "    predictions = torch.argmax(logits)\n",
        "\n",
        "    print(text + \" - \" + id2label[predictions.tolist()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2pSfe9yOho3",
        "outputId": "755f347b-2b47-4006-f399-9241cc4549d5"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Untrained model predictions:\n",
            "----------------------------\n",
            "The most greatest of all time - Negative\n",
            "It was good. - Negative\n",
            "Not a fan, don't recommed. - Negative\n",
            "Better than the first one. - Negative\n",
            "This is not worth watching even once. - Negative\n",
            "This one is a pass. - Negative\n",
            "I Love This - Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating the untrained Base Model befoe Fine tuning it and its as good as flipping a coin duh"
      ],
      "metadata": {
        "id": "Zf3jFdZyWIO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the Model using Peft for our Lora Model\n",
        "peft_config = LoraConfig(task_type=\"SEQ_CLS\", #Sequence Classification\n",
        "                        r=4, #intrinsic rank\n",
        "                        lora_alpha=32, #this is like a learning rate\n",
        "                        lora_dropout=0.01, #probability of the dropout rate\n",
        "                        target_modules = ['q_lin']) #applying loar to query layer, yay!"
      ],
      "metadata": {
        "id": "nfXcFx_YOeun"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peft_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueIvJc8gOeso",
        "outputId": "f3c6a40a-bf57-4a95-991b-86cb95db432e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='SEQ_CLS', inference_mode=False, r=4, target_modules={'q_lin'}, lora_alpha=32, lora_dropout=0.01, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zN2pFP0Oeqy",
        "outputId": "ab604940-2aa6-4a42-c325-8c194c251f08"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 628,994 || all params: 67,584,004 || trainable%: 0.9307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameters declared\n",
        "lr = 1e-3\n",
        "batch_size = 2\n",
        "num_epochs = 3"
      ],
      "metadata": {
        "id": "RsBFFv06OepS"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir= model_checkpoint + \"-lora-text-classification2\",\n",
        "    learning_rate=lr,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB7pH_94OenH",
        "outputId": "c569337e-8fe2-4f8f-b527-fdf76a855f2a"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dh03TNv4BBZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9cPmn84eBBWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plug Everything to this Trainer Class"
      ],
      "metadata": {
        "id": "RNFNBa7_Xq1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a creater trainer object\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer, #r u there\n",
        "    data_collator=data_collator, # this will dynamically pad examples in each batch to be equal length\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "cJibF7aFOei_"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model is under-training\n",
        "trainer.train() #heyy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "b6WrGkKxOefl",
        "outputId": "96cded46-6cff-4553-f77d-10f5e8eae015"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1500/1500 1:50:52, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.647900</td>\n",
              "      <td>0.715791</td>\n",
              "      <td>{'accuracy': 0.848}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.397300</td>\n",
              "      <td>0.591255</td>\n",
              "      <td>{'accuracy': 0.881}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.168600</td>\n",
              "      <td>0.746752</td>\n",
              "      <td>{'accuracy': 0.887}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"{'accuracy': 0.848}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.881}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.887}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1500, training_loss=0.40459475708007814, metrics={'train_runtime': 6661.6957, 'train_samples_per_second': 0.45, 'train_steps_per_second': 0.225, 'total_flos': 276964641291312.0, 'train_loss': 0.40459475708007814, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "08GyI9ssOecY",
        "outputId": "ffa96a3d-2595-4467-809d-d501ae033d03"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 13:57]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"{'accuracy': 0.881}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.5912553668022156,\n",
              " 'eval_accuracy': {'accuracy': 0.881},\n",
              " 'eval_runtime': 839.8018,\n",
              " 'eval_samples_per_second': 1.191,\n",
              " 'eval_steps_per_second': 0.595,\n",
              " 'epoch': 3.0}"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu\n",
        "model.to('cpu') # moving to mps for Mac (can alternatively do 'cpu')\n",
        "\n",
        "print(\"Trained model predictions:\")\n",
        "print(\"--------------------------\")\n",
        "for text in text_list:\n",
        "    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(\"cpu\") # moving to mps for Mac (can alternatively do 'cpu')\n",
        "\n",
        "    logits = model(inputs).logits\n",
        "    predictions = torch.max(logits,1).indices\n",
        "\n",
        "    print(text + \" - \" + id2label[predictions.tolist()[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cStdRoZmOeZj",
        "outputId": "05bbd344-c783-408d-c348-6f639cdb36e4"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/nightly/cpu\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Trained model predictions:\n",
            "--------------------------\n",
            "The most greatest of all time - Positive\n",
            "It was good. - Positive\n",
            "Not a fan, don't recommed. - Negative\n",
            "Better than the first one. - Positive\n",
            "This is not worth watching even once. - Negative\n",
            "This one is a pass. - Negative\n",
            "I Love This - Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "\n",
        "# Assuming tokenizer and model are already loaded\n",
        "# id2label maps prediction to labels\n",
        "\n",
        "# Example text list for evaluation\n",
        "text_list = [\"It was not bad\",\"The movie was fantastic!\", \"The product is defective.\", \"Excellent service!\", \"Not worth the price.\"]\n",
        "\n",
        "# Ground truth labels (for example purposes, binary: 1 for positive, 0 for negative)\n",
        "true_labels = [0, 1, 0, 1, 0]\n",
        "\n",
        "# Store predictions\n",
        "predicted_labels = []\n",
        "\n",
        "# Move model to CPU (or MPS for Mac)\n",
        "model.to('cpu')\n",
        "\n",
        "print(\"Trained model predictions:\")\n",
        "print(\"--------------------------\")\n",
        "\n",
        "for text in text_list:\n",
        "    # Tokenize the text\n",
        "    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(\"cpu\")  # Adjust device as necessary\n",
        "\n",
        "    # Get model predictions\n",
        "    with torch.no_grad():\n",
        "        logits = model(inputs).logits\n",
        "\n",
        "    # Get predicted label (class with highest score)\n",
        "    predictions = torch.argmax(logits, dim=1).item()\n",
        "    predicted_labels.append(predictions)\n",
        "\n",
        "    # Print the prediction\n",
        "    print(f\"{text} - Predicted label: {id2label[predictions]}\")\n",
        "\n",
        "# Convert to numpy arrays for evaluation\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "true_labels = np.array(true_labels)\n",
        "\n",
        "# Calculate accuracy, precision, recall, and F1 score\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='binary')\n",
        "\n",
        "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeNUweKKOeWz",
        "outputId": "fbcaedcf-cc0a-497d-b7d2-1cc77c8ff6ba"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained model predictions:\n",
            "--------------------------\n",
            "It was not bad - Predicted label: Negative\n",
            "The movie was fantastic! - Predicted label: Positive\n",
            "The product is defective. - Predicted label: Negative\n",
            "Excellent service! - Predicted label: Positive\n",
            "Not worth the price. - Predicted label: Negative\n",
            "\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-score: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FZOfGyVhOeT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DluYNskxOeQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o7XzXB3zOeN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pv5HOV5_OeKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8_J8g_VPOeIC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}